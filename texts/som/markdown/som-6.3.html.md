<div class="chapnav">

<span class="prev">Previous: [signals and
signs](./som-6.2.html)</span><span class="next">Next:
[B-Brains](./som-6.4.html)</span><span
class="contents">[Contents](index.html)</span>
<div class="titlebar">

Society of Mind
===============

</div>

</div>

*6.3* thought-experiments
-------------------------

How do you discover things about the world? Just look and see! It seems
simple — but it's not. Each casual glance employs a billion brain cells
to represent the present scene and to summarize its differences from
records of other experiences. Your agencies formulate little bits of
theories about what happens in the world and then make you do small
experiments to confirm or reformulate those conjectures. It only seems
simple because you're unaware of what is happening.

How do you discover things about your mind? You use a similar technique.
You make up little bits of theories about how you think, then test them
with tiny experiments. The trouble is that thought-experiments don't
often lead to the sorts of clear, crisp findings that scientists seek.
Ask yourself what happens when you try to imagine a round square — or
when you try to be happy and sad at the same time. Why is it so hard to
describe the results of such experiments or draw useful conclusions from
them? It is because we get confused. Our thoughts about our
mind-experiments are mind-experiments themselves — and therefore
interfere with one another.

Thinking affects our thoughts.

People who program computers encounter similar problems when new
programs malfunction because of unexpected interactions among their
parts. To find out what's happening, programmers have developed special
programs for *debugging* other programs. But just as in
thought-experiments, there is a danger that the program being watched
might change the one that's watching it. To prevent this, all modern
computers are equipped with special *interruption* machinery that
detects any other program's attempt to alter a debugging program; when
this happens, the culprit is *frozen* in its tracks so that the
debugging program can examine it. To do this, the interruption machinery
must be supplied with a private memory bank that can store enough
information to make it possible, later, to restart the frozen program as
though nothing had happened.

Are brains equipped to do similar things? It was easy to build
self-examination systems into computers that did only one thing at a
time, but it would be much harder to do in a system that, like the
brain, engages many processes at once. The problem is that if you were
to freeze only one process without stopping the others, it would change
the situation you're trying to examine. However, if you were to stop all
those processes all at once, you couldn't experiment on how they
interact.

Later, we'll see that consciousness is connected with our most immediate
memories. This means that there are limits on what consciousness can
tell us about itself — because it can't do perfect self-experiments.
That would require keeping perfect records of what happens inside one's
memory machinery. But any such machinery must get confused by
self-experiments that try to find out how it works — since such
experiments must change the very records they are trying to inspect! We
cannot handle interruptions perfectly. This doesn't mean that
consciousness cannot be understood, in principle. It only means that to
study it, we'll have to use the less direct methods of science, because
we cannot simply *look and see.*

<div class="footer">

[![Creative Commons
License](http://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png)](http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US)\
\
[![](./images/som_book.jpeg){#book}
![](./images/a_logo_17.gif)](http://www.amazon.com/gp/product/0671657135?ie=UTF8&camp=1789&creativeASIN=0671657135&linkCode=xm2&tag=marvinminsky)

</div>
